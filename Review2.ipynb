[ ]
from google.colab import drive
drive.mount('/content/drive')
Mounted at /content/drive

[ ]
import pandas as pd
df = pd.read_csv("/content/drive/MyDrive/airline.csv")

[ ]
df.head()

[ ]
len(df['aircraft'].unique())
364
[ ]
count_0 = df[df['recommended'] == 0].shape[0]
count_1 = df[df['recommended'] == 1].shape[0]

# Print the counts
print("Count of 0:", count_0)
print("Count of 1:", count_1)
Count of 0: 19298
Count of 1: 22098
Check for the NAN Values

[ ]
df.isnull().sum()
airline_name                         0
link                                 0
title                                0
author                               0
author_country                    1591
date                                 0
content                              0
aircraft                         40118
type_traveller                   39018
cabin_flown                       2876
route                            39055
overall_rating                    4535
seat_comfort_rating               7690
cabin_staff_rating                7688
food_beverages_rating             8132
inflight_entertainment_rating    10282
ground_service_rating            39193
wifi_connectivity_rating         40831
value_money_rating                1673
recommended                          0
dtype: int64
Impute the Missing values using mode and mean

[ ]
import pandas as pd
from sklearn.impute import SimpleImputer

numerical_imputer = SimpleImputer(strategy='mean')
numerical_columns = ['overall_rating', 'seat_comfort_rating', 'cabin_staff_rating',
                     'food_beverages_rating', 'inflight_entertainment_rating',
                     'ground_service_rating', 'wifi_connectivity_rating', 'value_money_rating']
df[numerical_columns] = numerical_imputer.fit_transform(df[numerical_columns])

categorical_columns = ['airline_name', 'link', 'title', 'author', 'author_country', 'date',
                       'content', 'aircraft', 'type_traveller', 'cabin_flown', 'route', 'recommended']
for col in categorical_columns:
    mode_value = df[col].mode()[0]
    df[col].fillna(mode_value, inplace=True)

[ ]
df.isnull().sum()
airline_name                     0
link                             0
title                            0
author                           0
author_country                   0
date                             0
content                          0
aircraft                         0
type_traveller                   0
cabin_flown                      0
route                            0
overall_rating                   0
seat_comfort_rating              0
cabin_staff_rating               0
food_beverages_rating            0
inflight_entertainment_rating    0
ground_service_rating            0
wifi_connectivity_rating         0
value_money_rating               0
recommended                      0
dtype: int64
[ ]
df.shape
(41396, 20)
LSTM MODEL ARCHITECTURE

Study of Embeded layer working

[ ]
from tensorflow.keras.preprocessing.text import one_hot
sent=[  'the glass of milk',
     'the glass of juice',
     'the cup of tea',
    'I am a good boy',
     'I am a good developer',
     'understand the meaning of words',
     'your videos are good',]
sent
['the glass of milk',
 'the glass of juice',
 'the cup of tea',
 'I am a good boy',
 'I am a good developer',
 'understand the meaning of words',
 'your videos are good']
[ ]
voc_size=10000
onehot_repr=[one_hot(words,voc_size)for words in sent]
print(onehot_repr)
[[6905, 3206, 9545, 2180], [6905, 3206, 9545, 5047], [6905, 3157, 9545, 6432], [5814, 7266, 3906, 9926, 3491], [5814, 7266, 3906, 9926, 1866], [7529, 6905, 1864, 9545, 3745], [2302, 596, 5644, 9926]]
[ ]
from tensorflow.keras.layers import Embedding
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
import numpy as np
sent_length=8
embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)
print(embedded_docs[0])
[   0    0    0    0 6905 3206 9545 2180]
[ ]
dim=10
model=Sequential()
model.add(Embedding(voc_size,10,input_length=sent_length))
model.compile('adam','mse')
print(model.predict(embedded_docs[0]))

1/1 [==============================] - 0s 142ms/step
[[ 0.03966243 -0.02700122  0.01282727 -0.03919796  0.03546575  0.03735317
   0.0134198   0.02262491 -0.02265506 -0.01190779]
 [ 0.03966243 -0.02700122  0.01282727 -0.03919796  0.03546575  0.03735317
   0.0134198   0.02262491 -0.02265506 -0.01190779]
 [ 0.03966243 -0.02700122  0.01282727 -0.03919796  0.03546575  0.03735317
   0.0134198   0.02262491 -0.02265506 -0.01190779]
 [ 0.03966243 -0.02700122  0.01282727 -0.03919796  0.03546575  0.03735317
   0.0134198   0.02262491 -0.02265506 -0.01190779]
 [ 0.00659917 -0.03849798  0.04551448  0.02484219  0.03573677  0.0220562
  -0.04290304 -0.02044612  0.00953165 -0.04391625]
 [ 0.01370395  0.01946678 -0.01895728 -0.01610043  0.00591592  0.03747046
  -0.00352254 -0.01361462  0.03337574 -0.01372613]
 [ 0.03019515  0.01602234  0.02878319 -0.01600127  0.00909529 -0.00248798
   0.02213674  0.02363398  0.04250691 -0.02826705]
 [-0.03908405  0.04836793  0.00390763 -0.03913062  0.04710421 -0.04673989
   0.04817729  0.02060978 -0.00780581  0.03455261]]
VADER - SENTIMENT ANALYSIS for content Classification (Positive,Negtive,Neutral)

[ ]
!pip install vaderSentiment
Collecting vaderSentiment
  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.0/126.0 kB 1.0 MB/s eta 0:00:00
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vaderSentiment) (2.31.0)
Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.2.0)
Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.4)
Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2.0.4)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2023.7.22)
Installing collected packages: vaderSentiment
Successfully installed vaderSentiment-3.3.2
[ ]
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

[ ]
obj = SentimentIntensityAnalyzer()
[ ]
print(obj.polarity_scores("The flight was on time and the service was satisfactory."))
{'neg': 0.0, 'neu': 0.783, 'pos': 0.217, 'compound': 0.3612}
[ ]
 print(obj.polarity_scores("The flight was good but high cost."))
{'neg': 0.0, 'neu': 0.755, 'pos': 0.245, 'compound': 0.2382}
[ ]
print(obj.polarity_scores("Terrible experience, rude staff and delayed flight.",))
{'neg': 0.667, 'neu': 0.333, 'pos': 0.0, 'compound': -0.7906}
[ ]
print(obj.polarity_scores( "Outbound flight FRA/PRN A319. 2 hours 10 min flight. I thought drinks/snacks for sale but sandwich soft drinks were served complimentary. Inbound flights SKP/LJU/FRA CRJ900. each 1 hour 30 min flight. Skyshop menu was in a seat pocket and drinks/snacks were for sale. All flight crews were friendly. Security check at the Ljubljana airport for transit passengers was chaos however it's possible to go to a gate within 30min.",
))
{'neg': 0.062, 'neu': 0.8, 'pos': 0.138, 'compound': 0.7351}
[ ]
import pandas as pd
import matplotlib.pyplot as plt


first_5_content_values = df['content']

sid = SentimentIntensityAnalyzer()

sentiments = []
positive_count = 0
negative_count = 0
neutral_count = 0

for content in first_5_content_values:
    sentiment_scores = sid.polarity_scores(content)
    max_sentiment = max(sentiment_scores, key=sentiment_scores.get)
    sentiments.append(max_sentiment)

    if max_sentiment == 'pos':
        positive_count += 1
    elif max_sentiment == 'neg':
        negative_count += 1
    else:
        neutral_count += 1

sentiment_labels = ['Positive', 'Negative', 'Neutral']
sentiment_counts = [positive_count, negative_count, neutral_count]

plt.bar(sentiment_labels, sentiment_counts, color=['green', 'red', 'blue'])
plt.xlabel('Sentiment')
plt.ylabel('Count')
plt.title('Sentiment Distribution')
plt.show()
[ ]
import pandas as pd
import matplotlib.pyplot as plt


cabin_counts = df['cabin_flown'].value_counts()

cabin_counts.plot(kind='bar', color=['blue', 'green', 'red', 'purple', 'orange'])

plt.xlabel('Cabin Flown')
plt.ylabel('Count')
plt.title('Distribution of Cabin Flown')
plt.xticks(rotation=0)
plt.show()

[ ]
import pandas as pd
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
df.boxplot(column='overall_rating', by='cabin_flown', vert=False, patch_artist=True)

plt.xlabel('Cabin Flown')
plt.ylabel('Overall Rating')
plt.title('Customer Satisfaction by Cabin Flown')
plt.xticks(rotation=0)
plt.ylim(0, 10)
plt.show()

[ ]
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout

X = df['content']
y = df['recommended']

sample_size = 1000
X_sample, _, y_sample, _ = train_test_split(X, y, train_size=sample_size, stratify=y, random_state=42)

X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)

tokenizer = Tokenizer()
tokenizer.fit_on_texts(X_train)

X_train_seq = tokenizer.texts_to_sequences(X_train)
X_test_seq = tokenizer.texts_to_sequences(X_test)

max_sequence_length = 100
X_train_pad = pad_sequences(X_train_seq, maxlen=max_sequence_length)
X_test_pad = pad_sequences(X_test_seq, maxlen=max_sequence_length)

model = Sequential()
model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=400, input_length=max_sequence_length))
model.add(Bidirectional(LSTM(units=256, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)))
model.add(Bidirectional(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2)))
model.add(Dense(units=64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(units=32, activation='relu'))  # Additional fully connected layer
model.add(Dense(units=1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

batch_size = 64
epochs = 20
history = model.fit(X_train_pad, y_train, validation_data=(X_test_pad, y_test), batch_size=batch_size, epochs=epochs)

loss, accuracy = model.evaluate(X_test_pad, y_test)
print(f"Test Loss: {loss}, Test Accuracy: {accuracy}")

y_pred = model.predict(X_test_pad)
y_pred_classes = (y_pred > 0.5).astype(int)

class_report = classification_report(y_test, y_pred_classes)
print("Classification Report:\n", class_report)

conf_matrix = confusion_matrix(y_test, y_pred_classes)

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="binary", cbar=False)
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix")
plt.show()
Identify Correlation for performing Classification Algorithms

[ ]

correlation_matrix = df.corr()['recommended']


correlation_matrix

<ipython-input-26-8a3b7f8957c9>:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  correlation_matrix = df.corr()['recommended']
overall_rating                   0.804600
seat_comfort_rating              0.598126
cabin_staff_rating               0.659564
food_beverages_rating            0.534056
inflight_entertainment_rating    0.360412
ground_service_rating            0.173719
wifi_connectivity_rating         0.077884
value_money_rating               0.773151
recommended                      1.000000
Name: recommended, dtype: float64
SVM

[ ]
import pandas as pd
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

features = ['seat_comfort_rating', 'cabin_staff_rating', 'food_beverages_rating',
            'inflight_entertainment_rating', 'ground_service_rating', 'wifi_connectivity_rating']
target = 'recommended'

X = df[features]
y = df[target]

imputer = SimpleImputer(strategy='mean')
X = imputer.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

svm = SVC()
svm.fit(X_train, y_train)

y_pred_svm = svm.predict(X_test)

accuracy = accuracy_score(y_test, y_pred_svm)
print("Accuracy:", accuracy)

f1 = f1_score(y_test, y_pred_svm)
print("F1 Score:", f1)

conf_matrix = confusion_matrix(y_test, y_pred_svm)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="binary", cbar=False)
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix")
plt.show()

class_report = classification_report(y_test, y_pred_svm)
print("Classification Report:\n", class_report)

DECISION TREE

[ ]
import pandas as pd
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn.model_selection import train_test_split

from sklearn.impute import SimpleImputer
import pydotplus
from IPython.display import Image
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, f1_score
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns


df['overall_rating'] = pd.to_numeric(df['overall_rating'], errors='coerce')

features = ['seat_comfort_rating', 'cabin_staff_rating', 'food_beverages_rating',
            'inflight_entertainment_rating', 'ground_service_rating', 'wifi_connectivity_rating']
target = 'recommended'

X = df[features]
y = df[target]

imputer = SimpleImputer(strategy='mean')

X = imputer.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)

y_pred_dt = dt.predict(X_test)


accuracy = accuracy_score(y_test, y_pred_dt)
print("Accuracy:", accuracy)

f1 = f1_score(y_test, y_pred_dt)
print("F1 Score:", f1)


conf_matrix = confusion_matrix(y_test, y_pred_dt)

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="binary", cbar=False)
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix")
plt.show()


class_report = classification_report(y_test,y_pred_dt)
print("Classification Report:\n", class_report)



dot_data = export_graphviz(dt, out_file=None, feature_names=features, class_names=['0', '1'], filled=True)

graph = pydotplus.graph_from_dot_data(dot_data)
Image(graph.create_png())


Logistic Regression

[ ]
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import numpy as np

lstm_outputs = np.random.rand(100, 1)
svm_outputs = np.random.rand(100, 1)
dt_outputs = np.random.rand(100, 1)

combined_outputs = np.hstack((lstm_outputs, svm_outputs, dt_outputs))

target_labels = np.random.randint(2, size=100)

X_train, X_test, y_train, y_test = train_test_split(
    combined_outputs, target_labels, test_size=0.2, random_state=42)

lr_model = LogisticRegression()

lr_model.fit(X_train, y_train)

lr_predictions = lr_model.predict(X_test)

accuracy = accuracy_score(y_test, lr_predictions)
print(f"LR Model Accuracy: {accuracy:.2f}")

LR Model Accuracy: 0.60
ENSEMBLING LSTM & DECISION TREE

[ ]
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from keras.models import Sequential
from keras.layers import LSTM, Dense
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns


df['overall_rating'] = pd.to_numeric(df['overall_rating'], errors='coerce')
X = df[['overall_rating']].values
y = df['recommended'].values

imputer = SimpleImputer(strategy='mean')
X = imputer.fit_transform(X)
y = np.where(y > 0, 1, 0)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

lstm_model = Sequential()
lstm_model.add(LSTM(64, activation='relu', input_shape=(1, 1)))
lstm_model.add(Dense(1, activation='sigmoid'))
lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
lstm_model.fit(X_train.reshape(-1, 1, 1), y_train, epochs=10, batch_size=32)

dt_model = DecisionTreeClassifier()
dt_model.fit(X_train, y_train)

lstm_predictions = lstm_model.predict(X_test.reshape(-1, 1, 1))
dt_predictions = dt_model.predict(X_test)

ensemble_predictions = np.round((lstm_predictions.flatten() + dt_predictions) / 2)

lstm_accuracy = accuracy_score(y_test, lstm_predictions.round())
dt_accuracy = accuracy_score(y_test, dt_predictions)
ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)

print("Ensemble Accuracy:", ensemble_accuracy)


print("\nClassification Report for Ensemble:")
print(classification_report(y_test, ensemble_predictions))

def plot_confusion_matrix(conf_matrix, title):
    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="binary")
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title(title)
    plt.show()



conf_matrix_ensemble = confusion_matrix(y_test, ensemble_predictions)
plot_confusion_matrix(conf_matrix_ensemble, 'Confusion Matrix for Ensemble')

ENSEMBLING LSTM & SVM & DECISION TREE

[ ]
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from keras.models import Sequential
from keras.layers import LSTM, Dense
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC


df['overall_rating'] = pd.to_numeric(df['overall_rating'], errors='coerce')
X = df[['overall_rating']].values
y = df['recommended'].values

imputer = SimpleImputer(strategy='mean')
X = imputer.fit_transform(X)
y = np.where(y > 0, 1, 0)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

lstm_model = Sequential()
lstm_model.add(LSTM(64, activation='relu', input_shape=(1, 1)))
lstm_model.add(Dense(1, activation='sigmoid'))
lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
lstm_model.fit(X_train.reshape(-1, 1, 1), y_train, epochs=10, batch_size=32)

dt_model = DecisionTreeClassifier()
dt_model.fit(X_train, y_train)

svm_model = SVC(kernel='linear', probability=True)
svm_model.fit(X_train, y_train)

lstm_predictions = lstm_model.predict(X_test.reshape(-1, 1, 1))
dt_predictions = dt_model.predict(X_test)
svm_predictions = svm_model.predict(X_test)

ensemble_predictions = np.round((lstm_predictions.flatten() + dt_predictions + svm_predictions) / 3)

lstm_accuracy = accuracy_score(y_test, lstm_predictions.round())
dt_accuracy = accuracy_score(y_test, dt_predictions)
svm_accuracy = accuracy_score(y_test, svm_predictions)
ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)

lstm_f1_score = f1_score(y_test, lstm_predictions.round())
dt_f1_score = f1_score(y_test, dt_predictions)
svm_f1_score = f1_score(y_test, svm_predictions)
ensemble_f1_score = f1_score(y_test, ensemble_predictions)



print("\nEnsemble Accuracy:", ensemble_accuracy)
print("Ensemble F1 Score:", ensemble_f1_score)

conf_matrix_lstm = confusion_matrix(y_test, lstm_predictions.round())
print("\nConfusion Matrix for LSTM:")
print(conf_matrix_lstm)
print("\nClassification Report for LSTM:")
print(classification_report(y_test, lstm_predictions.round()))

conf_matrix_dt = confusion_matrix(y_test, dt_predictions)
print("\nConfusion Matrix for Decision Tree:")
print(conf_matrix_dt)
print("\nClassification Report for Decision Tree:")
print(classification_report(y_test, dt_predictions))

conf_matrix_svm = confusion_matrix(y_test, svm_predictions)
print("\nConfusion Matrix for SVM:")
print(conf_matrix_svm)
print("\nClassification Report for SVM:")
print(classification_report(y_test, svm_predictions))

conf_matrix_ensemble = confusion_matrix(y_test, ensemble_predictions)
print("\nConfusion Matrix for Ensemble:")
print(conf_matrix_ensemble)
print("\nClassification Report for Ensemble:")
print(classification_report(y_test, ensemble_predictions))

Epoch 1/10
1035/1035 [==============================] - 5s 2ms/step - loss: 0.3237 - accuracy: 0.8504
Epoch 2/10
1035/1035 [==============================] - 3s 3ms/step - loss: 0.2273 - accuracy: 0.9292
Epoch 3/10
1035/1035 [==============================] - 4s 4ms/step - loss: 0.2268 - accuracy: 0.9292
Epoch 4/10
1035/1035 [==============================] - 6s 6ms/step - loss: 0.2268 - accuracy: 0.9283
Epoch 5/10
1035/1035 [==============================] - 4s 4ms/step - loss: 0.2265 - accuracy: 0.9278
Epoch 6/10
1035/1035 [==============================] - 2s 2ms/step - loss: 0.2265 - accuracy: 0.9290
Epoch 7/10
1035/1035 [==============================] - 2s 2ms/step - loss: 0.2260 - accuracy: 0.9280
Epoch 8/10
1035/1035 [==============================] - 3s 2ms/step - loss: 0.2269 - accuracy: 0.9249
Epoch 9/10
1035/1035 [==============================] - 4s 3ms/step - loss: 0.2259 - accuracy: 0.9292
Epoch 10/10
1035/1035 [==============================] - 3s 3ms/step - loss: 0.2261 - accuracy: 0.9289
259/259 [==============================] - 1s 2ms/step

Ensemble Accuracy: 0.9300724637681159
Ensemble F1 Score: 0.9310796333769789

Confusion Matrix for LSTM:
[[3790   76]
 [ 503 3911]]

Classification Report for LSTM:
              precision    recall  f1-score   support

           0       0.88      0.98      0.93      3866
           1       0.98      0.89      0.93      4414

    accuracy                           0.93      8280
   macro avg       0.93      0.93      0.93      8280
weighted avg       0.94      0.93      0.93      8280


Confusion Matrix for Decision Tree:
[[3668  198]
 [ 256 4158]]

Classification Report for Decision Tree:
              precision    recall  f1-score   support

           0       0.93      0.95      0.94      3866
           1       0.95      0.94      0.95      4414

    accuracy                           0.95      8280
   macro avg       0.94      0.95      0.94      8280
weighted avg       0.95      0.95      0.95      8280


Confusion Matrix for SVM:
[[3790   76]
 [ 503 3911]]

Classification Report for SVM:
              precision    recall  f1-score   support

           0       0.88      0.98      0.93      3866
           1       0.98      0.89      0.93      4414

    accuracy                           0.93      8280
   macro avg       0.93      0.93      0.93      8280
weighted avg       0.94      0.93      0.93      8280


Confusion Matrix for Ensemble:
[[3790   76]
 [ 503 3911]]

Classification Report for Ensemble:
              precision    recall  f1-score   support

           0       0.88      0.98      0.93      3866
           1       0.98      0.89      0.93      4414

    accuracy                           0.93      8280
   macro avg       0.93      0.93      0.93      8280
weighted avg       0.94      0.93      0.93      8280

[ ]
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from keras.models import Sequential
from keras.layers import LSTM, Dense
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
import matplotlib.pyplot as plt
import seaborn as sns

df['overall_rating'] = pd.to_numeric(df['overall_rating'], errors='coerce')
X = df[['overall_rating']].values
y = df['recommended'].values

imputer = SimpleImputer(strategy='mean')
X = imputer.fit_transform(X)
y = np.where(y > 0, 1, 0)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

lstm_model = Sequential()
lstm_model.add(LSTM(64, activation='relu', input_shape=(1, 1)))
lstm_model.add(Dense(1, activation='sigmoid'))
lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
lstm_model.fit(X_train.reshape(-1, 1, 1), y_train, epochs=10, batch_size=32)

dt_model = DecisionTreeClassifier()
dt_model.fit(X_train, y_train)

svm_model = SVC(kernel='linear', probability=True)
svm_model.fit(X_train, y_train)

lstm_predictions = lstm_model.predict(X_test.reshape(-1, 1, 1))
dt_predictions = dt_model.predict(X_test)
svm_predictions = svm_model.predict(X_test)

ensemble_predictions = np.round((lstm_predictions.flatten() + dt_predictions + svm_predictions) / 3)

lstm_accuracy = accuracy_score(y_test, lstm_predictions.round())
dt_accuracy = accuracy_score(y_test, dt_predictions)
svm_accuracy = accuracy_score(y_test, svm_predictions)
ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)

lstm_f1_score = f1_score(y_test, lstm_predictions.round())
dt_f1_score = f1_score(y_test, dt_predictions)
svm_f1_score = f1_score(y_test, svm_predictions)
ensemble_f1_score = f1_score(y_test, ensemble_predictions)




print("\nClassification Report for Ensemble:")
print(classification_report(y_test, ensemble_predictions))

def plot_confusion_matrix(conf_matrix, title):
    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="binary")
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title(title)
    plt.show()


conf_matrix_ensemble = confusion_matrix(y_test, ensemble_predictions)
plot_confusion_matrix(conf_matrix_ensemble, 'Confusion Matrix for Ensemble')


Random Forest

[ ]
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

classification_threshold = 0.7

features = df[['overall_rating', 'seat_comfort_rating', 'cabin_staff_rating',
               'food_beverages_rating', 'inflight_entertainment_rating',
               'ground_service_rating', 'wifi_connectivity_rating', 'value_money_rating']]

target = df['recommended']

binary_labels = (target >= classification_threshold).astype(int)

X_train, X_test, y_train, y_test = train_test_split(features, binary_labels, test_size=0.2, random_state=42)

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

rf_model.fit(X_train, y_train)

y_pred = rf_model.predict(X_test)

class_report = classification_report(y_test, y_pred)
print("Classification Report:\n", class_report)

conf_matrix = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="binary", cbar=False)
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix")
plt.show()

XG Boost

[ ]
import pandas as pd
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score

from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns




classification_threshold = 0.7
features = df[['overall_rating', 'seat_comfort_rating', 'cabin_staff_rating',
               'food_beverages_rating', 'inflight_entertainment_rating',
               'ground_service_rating', 'wifi_connectivity_rating', 'value_money_rating']]

target = df['recommended']

binary_labels = (target >= classification_threshold).astype(int)

X_train, X_test, y_train, y_test = train_test_split(features, binary_labels, test_size=0.2, random_state=42)

xgb_model = XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42)

xgb_model.fit(X_train, y_train)

y_pred_xgb = xgb_model.predict(X_test)

binary_pred_xgb = (y_pred_xgb >= classification_threshold).astype(int)

mse_xgb = mean_squared_error(y_test, binary_pred_xgb)
r2_xgb = r2_score(y_test, binary_pred_xgb)


accuracy_xgb = accuracy_score(y_test, binary_pred_xgb)

print("XGBoost - Mean Squared Error:", mse_xgb)
print("XGBoost - R-squared:", r2_xgb)
print("XGBoost - Classification Accuracy:", accuracy_xgb)


conf_matrix = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="binary", cbar=False)
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix")
plt.show()


class_report = classification_report(y_test, y_pred)
print("Classification Report:\n", class_report)

FACEBOOK PROPHET

[ ]
import pandas as pd
from prophet import Prophet
import matplotlib.pyplot as plt

classification_threshold = 0.7

prophet_data = df[['date', 'recommended']].copy()
prophet_data.rename(columns={'date': 'ds', 'recommended': 'y'}, inplace=True)

[ ]
prophet_data.head()
[ ]

train = prophet_data.iloc[:len(df)-365]
test = prophet_data.iloc[len(df)-365:]


[ ]
model=Prophet()
model.fit(train)
future = model.make_future_dataframe(periods=365)
forecast = model.predict(future)
INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.
DEBUG:cmdstanpy:input tempfile: /tmp/tmpnjzrb08v/ksiehtzj.json
DEBUG:cmdstanpy:input tempfile: /tmp/tmpnjzrb08v/u0cigig6.json
DEBUG:cmdstanpy:idx 0
DEBUG:cmdstanpy:running CmdStan, num_threads: None
DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=43114', 'data', 'file=/tmp/tmpnjzrb08v/ksiehtzj.json', 'init=/tmp/tmpnjzrb08v/u0cigig6.json', 'output', 'file=/tmp/tmpnjzrb08v/prophet_modelzfdwwriy/prophet_model-20230831054822.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']
05:48:22 - cmdstanpy - INFO - Chain [1] start processing
INFO:cmdstanpy:Chain [1] start processing
05:48:26 - cmdstanpy - INFO - Chain [1] done processing
INFO:cmdstanpy:Chain [1] done processing
[ ]

forecast.tail()

[ ]
forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()

[ ]
test.tail()

[ ]
prophet_data.columns
prophet_data.dropna(axis=0,inplace=True)
model.fit(prophet_data)
INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.
DEBUG:cmdstanpy:input tempfile: /tmp/tmpnjzrb08v/9h75qfne.json
DEBUG:cmdstanpy:input tempfile: /tmp/tmpnjzrb08v/lsrk14ag.json
DEBUG:cmdstanpy:idx 0
DEBUG:cmdstanpy:running CmdStan, num_threads: None
DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=93848', 'data', 'file=/tmp/tmpnjzrb08v/9h75qfne.json', 'init=/tmp/tmpnjzrb08v/lsrk14ag.json', 'output', 'file=/tmp/tmpnjzrb08v/prophet_model_naxuv18/prophet_model-20230831052547.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']
05:25:47 - cmdstanpy - INFO - Chain [1] start processing
INFO:cmdstanpy:Chain [1] start processing
05:25:54 - cmdstanpy - INFO - Chain [1] done processing
INFO:cmdstanpy:Chain [1] done processing
<prophet.forecaster.Prophet at 0x7fa3ab08b5e0>
[ ]
model.component_modes

{'additive': ['yearly',
  'weekly',
  'additive_terms',
  'extra_regressors_additive',
  'holidays'],
 'multiplicative': ['multiplicative_terms', 'extra_regressors_multiplicative']}
[ ]
future_dates=model.make_future_dataframe(periods=365)
[ ]
future_dates.tail()

[ ]

model.plot(forecast)
[ ]
model.plot_components(forecast)

[ ]
from statsmodels.tools.eval_measures import rmse

[ ]
predictions = prediction.iloc[-365:]['yhat']

[ ]
print("Root Mean Squared Error between actual and  predicted values: ",rmse(predictions,test['y']))
print("Mean Value of Test Dataset:", test['y'].mean())
Root Mean Squared Error between actual and  predicted values:  0.5003950819383851
Mean Value of Test Dataset: 0.5232876712328767

